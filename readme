- 언어 모델 학습기(learn_lm.py)와 랜덤 문장을 생성하기 위한 문장 생성기(generate_sentence.py)를 완성한다.
- 학습 모델은 한국어 어절 2-gram 기반의 언어 모델이다.

- 실행 방법
$ ./learn_lm.py 입력파일 출력파일
예) ./learn_lm.py news.txt news.lm.pickle

입력 파일 : 학습용 텍스트 파일 (한 줄에 한 문장)
출력 파일 : 학습된 모델(pickle 파일)

$ ./generate_sentence.py 입력파일
예) ./generate_sentence.py news.lm.pickle

입력 파일 : 학습된 모델(pickle 파일)

- 제출 파일 : learn_lm.py, generate_sentence.py (파일명을 수정하지 말 것! 압축 파일로 만들지 말 것!)

- 제출 마감 : 10월 22일 (수) 23:59:00까지



---

###  동작 단계별로 정리

1️⃣ 파일 한 줄씩 읽기  
   → 문장 단위로 처리해야 해.

2️⃣ 각 문장 앞뒤에 특수 토큰 `<s>`(start), `</s>`(end)`를 붙임.  
   → `"나는 밥을 먹는다"` → `["<s>", "나는", "밥을", "먹는다", "</s>"]`

3️⃣ 모든 단어를 돌면서
   - `unigram_counts[word] += 1`  
   - `(prev_word, current_word)` 쌍으로 bigram을 세기  
     예: `("<s>", "나는")`, `("나는", "밥을")`, `("밥을", "먹는다")`, `("먹는다", "</s>")`

---

### 🔢 결과 예시

unigram_counts (딕셔너리)
```python
{
    '<s>': 2,
    '나는': 2,
    '밥을': 1,
    '먹는다': 1,
    '학교에': 1,
    '간다': 1,
    '</s>': 2
}

bigram_counts
{
    '<s>': {'나는': 2},
    '나는': {'밥을': 1, '학교에': 1},
    '밥을': {'먹는다': 1},
    '먹는다': {'</s>': 1},
    '학교에': {'간다': 1},
    '간다': {'</s>': 1}
}
